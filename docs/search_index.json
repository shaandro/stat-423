[["index.html", "STAT 423 Review Guide 1 About", " STAT 423 Review Guide Shaandro Sarkar 1 About This is my review guide for STAT 423 (Nonparametric Statistics). The course was taught by Dr. Ya Su at Virginia Commonwealth University in the fall 2021 semester. "],["paired-two-sample-tests.html", "2 Paired Two-Sample Tests 2.1 Paired \\(t\\)-test 2.2 Sign test 2.3 Wilcoxon Signed-Rank Test 2.4 Permutation Test", " 2 Paired Two-Sample Tests Data for paired two-sample tests have the following properties: each subject \\(i\\) has two observations \\(X_i\\) and \\(Y_i\\) to give a paired observation \\((X_i, Y_i)\\) \\((X_1, Y_1), \\dots, (X_n, Y_n)\\) are independent Our general strategy is to perform one-sample tests on the paired difference \\(Z_i = Y_i - X_i\\) For this section, we will use the R dataset sleep. In this data, each subject was given both drug 1 and drug 2, and the change in their sleep was measured. The column group indicates which drug the subject took, and the column extra indicates the change in sleep. data(&quot;sleep&quot;) # X: effect on sleep from drug 1 x &lt;- sleep$extra[sleep$group == 1] # Y: effect on sleep from drug 2 y &lt;- sleep$extra[sleep$group == 2] # Z: paired difference between X and Y z &lt;- y - x For each of these tests, we will be testing the hypotheses \\(H_0\\): \\(\\mu = 0\\) vs \\(H_a\\): \\(\\mu \\neq 0\\), where \\(\\mu\\) is the mean of \\(Z\\). 2.1 Paired \\(t\\)-test Parametric test One-sample \\(t\\)-test on the mean \\(\\mu\\) of \\(Z\\) Assumption: \\(Z_i \\overset{\\mathrm{iid}} \\sim N(\\mu, \\sigma^2)\\) Hypotheses: \\(H_0\\): \\(\\mu = \\mu_0\\) vs \\(H_a\\): \\(\\mu \\neq \\mu_0\\) (or \\(&lt;\\), \\(&gt;\\)) Test statistic: \\[T_{\\mathrm{obs}} = \\frac{\\bar{Z} - \\mu_0}{s_Z / \\sqrt{n}},\\] where \\(\\bar{Z}\\) and \\(s_Z\\) are the sample mean and sample standard deviation of \\(Z\\) Null distribution: Under \\(H_0\\), \\(T_{\\mathrm{obs}} \\sim t_{n-1}\\) There are three ways to do this test in R using the function t.test. If the observations for group \\(X\\) and group \\(Y\\) are stored in separate vectors x and y, then we use t.test with the argument paired = TRUE. t.test(x, y, paired = TRUE, alternative = &quot;two.sided&quot;) ## ## Paired t-test ## ## data: x and y ## t = -4.0621, df = 9, p-value = 0.002833 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.4598858 -0.7001142 ## sample estimates: ## mean of the differences ## -1.58 If the paired differences \\(Z = Y - X\\) are stored in one vector z, then we use a one-sample t.test. t.test(z, alternative = &quot;two.sided&quot;) ## ## One Sample t-test ## ## data: z ## t = 4.0621, df = 9, p-value = 0.002833 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 0.7001142 2.4598858 ## sample estimates: ## mean of x ## 1.58 If the data is stored in one matrix or dataframe where one column contains the observations and another column contains the groups, we can use the following syntax. For this data, extra contains the observations, and group indicates which group each observation comes from. t.test(extra ~ group, paired = TRUE, data = sleep, alternative = &quot;two.sided&quot;) ## ## Paired t-test ## ## data: extra by group ## t = -4.0621, df = 9, p-value = 0.002833 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.4598858 -0.7001142 ## sample estimates: ## mean of the differences ## -1.58 The result for all three values is the same: \\(p\\text{-value} = 0.002833\\). 2.2 Sign test Also called binomial test Nonparametric test on the median \\(\\theta\\) of \\(Z\\) Assumption: \\(Z_i\\) are iid Hypotheses: \\(H_0\\): \\(\\theta = \\theta_0\\) vs \\(H_a\\): \\(\\theta \\neq \\theta_0\\) (or \\(&lt;\\), \\(&gt;\\)) Test statistic: \\[X = I\\{Z_i &gt; \\theta_0\\},\\] where \\(I\\{Z_i &gt; \\theta_0\\}\\) is the number of observations \\(Z_i\\) that are greater than \\(\\theta_0\\). Null distribution: Under \\(H_0\\), \\(X \\sim \\mathrm{Binom}(n, p = 0.5)\\) The alternative hypothesis \\(H_a\\): \\(\\theta &lt; 0\\) is equivalent to \\(H_a\\): \\(p &lt; 0.5\\), where \\(p = P(Z_i &gt; 0)\\). This is because, under \\(H_0\\): \\(\\theta = 0\\), the probability of \\(Z_i\\) being less than the median \\(\\theta\\) is 0.5. The test is conducted as follows. # calculate paired differences z &lt;- y - x # calculate the number of observations greater than 0 X &lt;- sum(z &gt; 0) # calculate p-value 2 * min(pbinom(X, size = length(z), prob = 0.5), 1 - pbinom(X, size = length(z), prob = 0.5)) ## [1] 0.001953125 2.3 Wilcoxon Signed-Rank Test Nonparametric test on the median \\(\\theta\\) of \\(Z\\) Assumptions: \\(Z_i\\) are iid and symmetric Hypotheses: \\(H_0\\): \\(\\theta = \\theta_0\\) vs \\(H_a\\): \\(\\theta \\neq \\theta_0\\) (or \\(&lt;\\), \\(&gt;\\)) Test statistic: \\[V = \\sum_{i = 1}^n I\\{Z_i &gt; \\theta_0\\} \\mathrm{rank}(|Z_i - \\theta_0|)\\] Like with the paired \\(t\\)-test, there are three ways to conduct the Wilcoxon test using wilcox.test. wilcox.test(x, y, paired = TRUE, alternative = &quot;two.sided&quot;) ## Warning in wilcox.test.default(x, y, paired = TRUE, alternative = &quot;two.sided&quot;): ## cannot compute exact p-value with ties ## Warning in wilcox.test.default(x, y, paired = TRUE, alternative = &quot;two.sided&quot;): ## cannot compute exact p-value with zeroes ## ## Wilcoxon signed rank test with continuity correction ## ## data: x and y ## V = 0, p-value = 0.009091 ## alternative hypothesis: true location shift is not equal to 0 wilcox.test(z, alternative = &quot;two.sided&quot;) ## Warning in wilcox.test.default(z, alternative = &quot;two.sided&quot;): cannot compute ## exact p-value with ties ## Warning in wilcox.test.default(z, alternative = &quot;two.sided&quot;): cannot compute ## exact p-value with zeroes ## ## Wilcoxon signed rank test with continuity correction ## ## data: z ## V = 45, p-value = 0.009091 ## alternative hypothesis: true location is not equal to 0 wilcox.test(extra ~ group, paired = TRUE, data = sleep, alternative = &quot;two.sided&quot;) ## Warning in wilcox.test.default(x = c(0.7, -1.6, -0.2, -1.2, -0.1, 3.4, 3.7, : ## cannot compute exact p-value with ties ## Warning in wilcox.test.default(x = c(0.7, -1.6, -0.2, -1.2, -0.1, 3.4, 3.7, : ## cannot compute exact p-value with zeroes ## ## Wilcoxon signed rank test with continuity correction ## ## data: extra by group ## V = 0, p-value = 0.009091 ## alternative hypothesis: true location shift is not equal to 0 Using all three methods, \\(p\\text{-value} = 0.009091\\). 2.4 Permutation Test Paired data \\((X_i, Y_i)\\), where \\(X_i\\) and \\(Y_i\\) are correlated Assumption: \\((X_1, Y_1), \\dots, (X_n, Y_n)\\) are iid For \\(n\\) subjects, there are \\(R = 2^n\\) equally likely permutation outcomes For each possible outcome \\(\\ell \\in \\{1, \\dots, R\\}\\), we calculate the sample mean of differences \\[z_\\ell = \\frac{1}{n} \\sum_{i=1}^n (Y_{\\ell i} - X_{\\ell i}),\\] where \\((X_{\\ell i}, Y_{\\ell i})\\) is the \\(i\\)th observation of the \\(\\ell\\)th permutation outcome. The \\(p\\)-value depends on the direction of \\(H_a\\). \\(H_a\\) \\(p\\)-value \\(\\mu &gt; 0\\) \\(I\\{z_\\ell \\geq \\bar{Z}\\} / R\\) \\(\\mu &lt; 0\\) \\(I\\{z_\\ell \\leq \\bar{Z}\\} / R\\) \\(\\mu \\neq 0\\) \\(I\\{|z_\\ell| \\geq |\\bar{Z}|\\} / R\\) 2.4.1 Exact permutation test The exact permutation test for \\(H_a\\): \\(\\mu \\neq 0\\) is performed as follows. # paired differences z &lt;- y - x # sample size n &lt;- length(z) # create permutation matrix lists &lt;- split(matrix(c(-1, 1), n, 2, byrow=TRUE), 1:n) all.outcomes &lt;- as.matrix(expand.grid(lists)) # observed test statistic zbar &lt;- mean(z) # test statistic for permutation samples zl &lt;- apply(all.outcomes, 1, function(u) mean(u*abs(z))) # p-value mean(abs(zl) &gt;= abs(zbar)) ## [1] 0.00390625 In this example, we used the sample mean as our test statistic, but the choice of test statistic for the permutation test is flexible. 2.4.2 Large-sample approximation for permutation test Instead of using all \\(R = 2^n\\) possible permutation outcomes, we can randomly select \\(R\\) permutation outcomes and calculate the approximate \\(p\\)-value. R &lt;- 1000 z &lt;- y - x n &lt;- length(z) # generate permutation matrix outcomes &lt;- replicate(R, sample(c(-1, 1), n, replace = TRUE)) # observed test statistic zbar &lt;- mean(z) # test statistic for permutation samples zl &lt;- apply(outcomes, 2, function(u) mean(u*abs(z))) # p-value mean(abs(zl) &gt;= abs(zbar)) ## [1] 0.003 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
